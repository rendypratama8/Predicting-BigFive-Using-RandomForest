{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8f41007",
   "metadata": {},
   "source": [
    "#### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bda067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from twarc import Twarc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "from collections import OrderedDict\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d8ec1b",
   "metadata": {},
   "source": [
    "#### Twitter API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cabc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = 'QqAbgf4o3hmXcPSAtvJUbMDil'\n",
    "consumer_secret = 'Oe1pap5PZXty7dF81oHEmbOH5OZ96M7IPavCXWmQVDeKeb8ouY'\n",
    "access_token = '1482704857-a2m5aEUobIZEMsRVzjZ4YI2wlGdrHKnZ1kmDbwj'\n",
    "access_token_secret = 'socWgQ256eFQQo0yGx5zSMQsUwoe7WYIeqd7fRc1ECjqf'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cc71c6",
   "metadata": {},
   "source": [
    "#### User Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7423646d",
   "metadata": {},
   "outputs": [],
   "source": [
    "username= ['alfian_ay', 'Canc_ers', 'lenoydew', 'Chyntw_', 'stttopp', 'savirapu',  'gorjesparkle', 'hasinaNr','latifanajla__', 'Dyeah13', 'aliencuk', 'detiaferlian', 'putriyuniardi', 'fildzahanais', 'imfnia', \n",
    "           'stephanieayuu', 'farahmhdyyh', 'rizkaaulia', 'ViraGutubela', 'kimsatgat2', 'Rizol_Rizal', 'mautongue','fanirchm27', 'rallyanta', 'yuliawafa', 'Zulijanis', 'haluhaluclubbb', 'nauli_permata', 'erickdidudidu', \n",
    "           'achadianrani', 'JulianDennis1', 'T_Gooners16', 'ichatarina', 'rizka_christian', 'Okyranda', 'evaxevi', 'Bettyindahr', 'micinsassae', 'Indahastikas', 'selftalker', 'ussiiyy', 'abcdenjiii', 'ekahanda', \n",
    "           'puten_hijau', 'Naddyadw', 'wydyudi_', 'Nysmonworld', 'afidazkyy', 'iqbalpaz', 'Gabriielle_L', 'NadyaUlfahN', 'astikhairunnisa', 'dwiahkam', 'tastyducky', 'Ghias_yusuf', 'Darna17', 'daranagas', \n",
    "           'jooshpn','azwardfauzan','dzakimadhani','alfrisadivaw','Idrisg8','arangkecap','chandnidevi','pocagurii','ysyni','yudkuswar','Joabaldo','pujaypujilpuu',\n",
    "           'MaulanaRiandi','vnyriany','awwlltl','anakyangtangkas','nisable23','akuuuberuang','kokocrvnch','fia_lutfiazhari','marisahafsyah94','oziechonky','Rzqmentari', 'introperti','lerinarin','imadamii','g1tsy','kerakteloorr',\n",
    "           'dellapj_','adlfynf','erisyaeris','miftahulilma10', 'alaaini1','Ociirosiana','Jollajoly','vnessapatricia','elzr13','rarraayu','deliahndt','Bananamilxxx','cipipiw','Anggycaa', 'rissaafh','nadihng','punyauname',\n",
    "           'nggitw','destandriyani','Saccharinande','Sora_Alxean','kepikbesar','rafitaasr','i_frankenstein','Alaniafitri','Yokozka','bukandove','silmiotmiot','Metinaayu_','elidoff','denokdhena',\n",
    "           'dheaniranabila','ki_cuu','v3isvthree','heyhestyy','timutiimuti','rvghalif','Trisawardanis','Zyoslin','munawaroh_mona','febbyjulietta','hkawilarangg','mellahae','ptorianns',\n",
    "           'a2lir','lilstep95','oneperson01_','Nurulainiii','diniheryani','apdesti_','rahmatfathoni','Nadiadjibran','tiaraindhprmt','Inkafbrn','ErvhanS','andiniayu','EmangGemeshin','ejakulasi_','Ariefpopoh','gramelt','Gebiyaeputri',\n",
    "           'astrifaj','tramadanur','duwaaaay','alitapuspa_','Fitrisip','yusrinasmarani','Abdee','almostbeyours','ursnflwr_','novitakurniap','Alfinalfinn','Januarrmdhn','Dwidys_',\n",
    "           'liayurh_','Isnakhairi','agus_trianto','iyaininajau','ovilsp','virraaa_','baksopangsitnya','liawrdhani','adinnda_ekhaa','puteriroro','tahtaallfina','meniaclosia','adityandr',\n",
    "           'yulfaariza','Rohanahrey','Sekarumn','Joeniararief','Linggaralfi','hlutami','R_fiika','hidadahida','iphune','vanillasvgar','kodelle_','Strybycy','Phoebee_ip','kalisnakal',\n",
    "           'rpdelimaa','Iffamee','Lulufrdni','shelfiw','adityosusanto_','grestina','yuaaayy','nneninot1996','taritahir','Shafiraara','dzakyhaidar__',\n",
    "           'granweastery','yuuta__96','egabetari','lailapurnamas','IndrasZLaila','Devaina','Nidakarin','fitriindy','Isnanarahma','pinochiao','ramdaneinstein','effendisgurl','mi_chiamo_joel','sfaui','dikmabelarosa',\n",
    "           'zea_mays07','Ni','okkyskripsi','NopiyNovi','artikakristi','ferrafbryn','amalinafitrah','salsabilabia','Indomilk','ibnubons','wequte','jehademusa','qthrnnada','Hapsarihn','chuggingtonn','naurakh',\n",
    "           'atikapuspi','kissst__','Fitripratiwi_pn','Penguntitkmvrt','Agustinurfika','LenteeraMerahh','inimella1','adamumemo','astridvivianni','ath_tobe','benrskbyg','boboxsiang','bojaktempur','citora_','dannytandean','driddv','firmanoktaf','jundie_m','krisnawah','leoagung98',\n",
    "           'rahmanizar_','riskaadesuryani','semesta_human','siti_sr137','ariantipp','Betyratih','ClarisaHasya','Fhrz99','fridamayanti','Esjaeruk','igonovaldi','Juliepuspita01','khelian_ni_s','Komalasari_ak','melyst94','nanasambara','niazmi_','pipaaw','Rotiisicoklat','salisnurk','Saraadaay',]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e089810",
   "metadata": {},
   "source": [
    "# Crawl Account Information Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cce3cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info1(username):\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "    api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "    \n",
    "#     outfile = \"datasets/#.csv\"\n",
    "    outfile = \"datasets/data-accounts-info/crawl-social-1.csv\"\n",
    "    with open(outfile, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow([\"username\", \"follower\", \"following\", \"favorite\",\"tweets\"])\n",
    "        for user in username:\n",
    "            max_tweets = 1 \n",
    "            # Creation of query method using parameters\n",
    "            tweets = tweepy.Cursor(api.user_timeline, id=user, tweet_mode='extended').items(max_tweets)\n",
    "            tweets_list = [[tweet.user.screen_name, tweet.user.followers_count, tweet.user.friends_count, tweet.user.favourites_count, tweet.user.statuses_count]for tweet in tweets]\n",
    "            csvwriter.writerows(tweets_list)\n",
    "\n",
    "    print(\"- Crawl Info Data 1 '\" + outfile + \"' complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442b0e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_info1(username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6122503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info2(username):\n",
    "    t = Twarc()\n",
    "    \n",
    "#     outfile = \"datasets/##.csv\"\n",
    "    outfile = \"datasets/data-accounts-info/crawl-social-2.csv\"\n",
    "    with open(outfile, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow([\"username\", \"retweet\", \"favorited\"])\n",
    "        for user in username:\n",
    "            total_favorited = 0\n",
    "            total_retweet = 0\n",
    "            for tweet in t.timeline(screen_name=user):\n",
    "                if 'retweeted_status' in tweet:\n",
    "                    total_retweet += 1\n",
    "                if tweet['favorite_count'] > 0:\n",
    "                    total_favorited += tweet['favorite_count']\n",
    "            \n",
    "            csvfile.write(str(user).lower()+','+str(total_retweet)+','+str(total_favorited))\n",
    "            csvfile.write('\\n')\n",
    "            print(user + \" successfully crawled\" + \" retweet \" + str(total_retweet) + \" favorited \" + str(total_favorited))\n",
    "    \n",
    "    print(\"- Crawl Info Data 2 '\" + outfile + \"' complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c76c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_info2(username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c81cf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "info1 = pd.read_csv('datasets/data-accounts-info/crawl-social-1.csv')\n",
    "info2 = pd.read_csv('datasets/data-accounts-info/crawl-social-2.csv')\n",
    "\n",
    "for i in range (len(info1['username'])):\n",
    "    info1['username'].loc[i] = str.lower(info1['username'].loc[i])\n",
    "    \n",
    "# using merge function by setting how='right'\n",
    "output = pd.merge(info1, info2, \n",
    "                   on='username', \n",
    "                   how='right')\n",
    "\n",
    "# output = output.drop_duplicates().reset_index(drop=True)\n",
    "output.to_csv(r'datasets/social-feature.csv', index = False, header=True)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9dd421",
   "metadata": {},
   "source": [
    "# Crawl Tweet Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0d61a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "crawl_tweets = []\n",
    "def get_tweets(username):\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "    api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "    limit = 1000\n",
    "\n",
    "    user_tweets = []\n",
    "    for tweet in tweepy.Cursor(api.user_timeline, screen_name=username, include_rts=False, tweet_mode='extended').items(limit):\n",
    "        actualTweet = re.sub(r'\\s+', ' ', tweet.full_text)\n",
    "        crawl_tweets.append([username, tweet.created_at, actualTweet])\n",
    "        user_tweets.append([username, tweet.created_at, actualTweet])\n",
    "\n",
    "    outfile = \"datasets/data-tweets/@\"+ username + \".csv\"\n",
    "    print(\"- crawl tweet data '\" + outfile + \"' complete.\")\n",
    "    with open(outfile, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow([\"username\", \"created_at\", \"text\"])\n",
    "        csvwriter.writerows(user_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8cbfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in username:\n",
    "    get_tweets(user)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d015e1",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db29c927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def casefolding(sent):\n",
    "    sent = sent.lower()\n",
    "    return sent\n",
    "\n",
    "def filtering(sent):\n",
    "    sent = re.sub(r'rt +@[^ :]+:?', ' ', sent) # retweet\n",
    "    sent = re.sub(r'@[^\\s]+', '', sent)  # @username\n",
    "    sent = re.sub(r'#([^\\s]+)', '', sent)  # hashtag\n",
    "    sent = re.sub(r'https:[^\\s]+', '', sent)  # URL links\n",
    "    sent = re.sub(r\"[.,:;+!\\-_<^/=?\\\"'\\(\\)\\d\\*]\", \" \", sent)  # symbol, char\n",
    "    sent = re.sub(r'[^\\x00-\\x7f]+', '', sent)  # non ASCII chars\n",
    "    sent = re.sub(r'\\s+', ' ', sent)  # duplicate whitespace\n",
    "    sent = re.sub(\"(.)\\\\1{2,}\", \"\\\\1\", sent) # char repeat\n",
    "    return sent\n",
    "\n",
    "def tokenizing(sent):\n",
    "    token = nltk.word_tokenize(sent)\n",
    "    return token\n",
    "\n",
    "def stemming(sent):\n",
    "    factorySt = StemmerFactory()\n",
    "    stemmer = factorySt.create_stemmer()\n",
    "    sent = stemmer.stem(sent)\n",
    "    return sent\n",
    "\n",
    "def slangWordConverting(sent):\n",
    "    slangwords = dict()\n",
    "    with open('datasets/dict/slang_all.csv') as wordfile:\n",
    "        for word in wordfile:\n",
    "            word = word.split(',')\n",
    "            slangwords[word[0]] = word[1].replace('\\n', '')\n",
    "\n",
    "    wordsArray, fixed = sent.split(' '), []\n",
    "    for word in wordsArray:\n",
    "        if word in slangwords:\n",
    "            word = slangwords[word]\n",
    "        fixed.append(word)\n",
    "        sent = ' '.join(fixed)\n",
    "    return sent\n",
    "\n",
    "def stopWordRemoving(sent):\n",
    "    factorySw = StopWordRemoverFactory()\n",
    "    stopword = factorySw.create_stop_word_remover()\n",
    "    sent = stopword.remove(sent)\n",
    "    return sent\n",
    "\n",
    "def getUserTweets(username):\n",
    "    columns = defaultdict(list)\n",
    "    infile = \"datasets/data-tweets/@\" + username + \".csv\"\n",
    "#     infile = \"datasets/user tweets/@\" + username + \".csv\"\n",
    "    with open(infile, 'r', encoding='utf-8') as tweetfile:\n",
    "        reader = csv.DictReader(tweetfile)\n",
    "        for row in reader:\n",
    "            for (k, v) in row.items():\n",
    "                columns[k].append(v)\n",
    "\n",
    "    outfile = \"datasets/data-tweets/preprocess/#pp@\" + username + \".csv\"\n",
    "#     outfile = \"Datasets/Preprocess/@\" + username + \".csv\"\n",
    "    with open(outfile, 'w') as userPreprocessed:\n",
    "        userPreprocessed.write('username,tweet')\n",
    "        userPreprocessed.write('\\n') \n",
    "        for tweet in columns['text']:\n",
    "            print('Original: '+str(nltk.word_tokenize(tweet)))\n",
    "            tweet = casefolding(str(tweet))\n",
    "            tweet = filtering(str(tweet))\n",
    "            tweet = tokenizing(tweet)\n",
    "            tweet = stemming(str(tweet))\n",
    "            tweet = slangWordConverting(str(tweet))\n",
    "            tweet = stopWordRemoving(str(tweet))            \n",
    "            \n",
    "            print('Processed: '+str(tweet) + '\\n')\n",
    "            if tweet != '':\n",
    "                userPreprocessed.write(str(username)+','+str(tweet))\n",
    "                userPreprocessed.write('\\n')\n",
    "\n",
    "    print(\"\\n- preprocess task '\" + outfile + \"' completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd6eba1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for user in username:\n",
    "    getUserTweets(user)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a789c7c2",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2f5180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TFIDF(username):\n",
    "    term = []\n",
    "    infile = \"datasets/data-tweets/preprocess/pp@\" + username + \".csv\"\n",
    "    with open(infile, 'r') as file:\n",
    "        i = 0\n",
    "        tweets = []\n",
    "        for row in file:\n",
    "            if i == 0:\n",
    "                i += 1\n",
    "                continue\n",
    "            row = row.split(',')[1]\n",
    "            row = row.split('\\n')[0]\n",
    "            tweets.append(row)\n",
    "        term = ' '.join(tweets)\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectors = vectorizer.fit_transform([term])\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    dense = vectors.todense()\n",
    "    denselist = dense.tolist()\n",
    "\n",
    "    outfile = \"datasets/data-tweets/tfidf/tfidf@\" + username + \".csv\"\n",
    "    with open(outfile, mode='w') as file:\n",
    "        file.write('term,weight\\n')\n",
    "        for i in range(len(feature_names)):\n",
    "            file.write(str(feature_names[i])+','+str(round(denselist[0][i], 3))+'\\n')\n",
    "\n",
    "    print(\"\\n- tf-idf task '\" + outfile + \"' complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5f94a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for user in username:\n",
    "    TFIDF(user)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55d7500",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea3ac37",
   "metadata": {},
   "source": [
    "#### Sentistrength Algorithm\n",
    "by: https://github.com/masdevid/sentistrength_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac3c985",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sentistrength:\n",
    "    def __init__(self, config=dict()):\n",
    "        self.negasi = [line.replace('\\n','') for line in open(\"datasets/dict/negatingword.txt\").read().splitlines()]\n",
    "        self.tanya = [line.replace('\\n','') for line in open(\"datasets/dict/questionword.txt\").read().splitlines()]\n",
    "        #create sentiment words dictionary\n",
    "        self.sentiwords_txt = [line.replace('\\n','').split(\":\") for line in open(\"datasets/dict/sentiwords_id.txt\").read().splitlines()]\n",
    "        self.sentiwords_dict = OrderedDict()\n",
    "        for term in self.sentiwords_txt:\n",
    "            self.sentiwords_dict[term[0]] = int(term[1])\n",
    "        #create emoticon dictionary\n",
    "        self.emoticon_txt = [line.replace('\\n','').split(\" | \") for line in open(\"datasets/dict/emoticon_id.txt\").read().splitlines()]\n",
    "        self.emoticon_dict = OrderedDict()\n",
    "        for term in self.emoticon_txt:\n",
    "            self.emoticon_dict[term[0]] = int(term[1])\n",
    "        #create idioms dictionary\n",
    "        self.idioms_txt = [line.replace('\\n','').split(\":\") for line in open(\"datasets/dict/idioms_id.txt\").read().splitlines()]\n",
    "        self.idioms_dict = OrderedDict()\n",
    "        for term in self.idioms_txt:\n",
    "            self.idioms_dict[term[0]] = int(term[1])\n",
    "        #create boosterwords dictionary\n",
    "        self.boosterwords_txt = [line.replace('\\n','').split(\":\") for line in open(\"datasets/dict/boosterwords_id.txt\").read().splitlines()]\n",
    "        self.boosterwords_dict = OrderedDict()\n",
    "        for term in self.boosterwords_txt:\n",
    "            self.boosterwords_dict[term[0]] = int(term[1])\n",
    "        self.negation_conf = config[\"negation\"]\n",
    "        self.booster_conf = config[\"booster\"]\n",
    "        self.ungkapan_conf = config[\"ungkapan\"]\n",
    "        self.consecutive_conf = config[\"consecutive\"]\n",
    "        self.repeated_conf = config[\"repeated\"]\n",
    "        self.emoticon_conf = config[\"emoticon\"]\n",
    "        self.question_conf = config[\"question\"]\n",
    "        self.exclamation_conf = config[\"exclamation\"]\n",
    "        self.punctuation_conf = config[\"punctuation\"]\n",
    "        self.mean_conf = False\n",
    "\n",
    "    def senti(self,term):\n",
    "        try:\n",
    "            return self.sentiwords_dict[term]\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "    def emosikon(self,term):\n",
    "        try:\n",
    "            return self.emoticon_dict[term]\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "    def ungkapan(self,term):\n",
    "        try:\n",
    "            return self.idioms_dict[term]\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "    def booster(self, term):\n",
    "        try:\n",
    "            return self.boosterwords_dict[term]\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "    def cek_negationword(self, prev_term, prev_term2):\n",
    "        #jika kata sebelumnya (index-1) adalah kata negasi, negasikan nilai -+nya\n",
    "        if prev_term in self.negasi or prev_term2+\" \"+prev_term in self.negasi:\n",
    "            # print prev_term\n",
    "            self.score = -abs(self.score) if self.score>0 else abs(self.score)\n",
    "\n",
    "    def cek_boosterword(self,term):\n",
    "        booster_score = self.booster(term)\n",
    "        if booster_score !=0 and self.score>0: self.score += booster_score\n",
    "        if booster_score !=0 and self.score<0: self.score -= booster_score\n",
    "\n",
    "    def cek_consecutive_term(self, prev_term):\n",
    "        if self.prev_score>0 and self.score >=3: self.score+=1 \n",
    "        if self.prev_score<0 and self.score <=-3: self.score-=1 \n",
    "\n",
    "    def cek_ungkapan(self, bigram,trigram, i):\n",
    "        bigram = ' '.join(bigram)\n",
    "        trigram = ' '.join(trigram)\n",
    "        ungkapan_score = self.ungkapan(bigram)\n",
    "        if ungkapan_score==0:\n",
    "            ungkapan_score = self.ungkapan(trigram)\n",
    "        if ungkapan_score!=0:\n",
    "            self.score = ungkapan_score\n",
    "            self.prev_score = 0\n",
    "            self.pre_max_pos[i-1] = 1\n",
    "            self.pre_max_neg[i-1] = -1\n",
    "            self.max_pos = self.pre_max_pos[i-2] #if len(self.pre_max_pos)>1 else 1\n",
    "            self.max_neg = self.pre_max_neg[i-2] #if len(self.pre_max_neg)>1 else -1\n",
    "            self.sentence_score[i-1] = re.sub(r'\\[\\d\\]','',self.sentence_score[i-1])\n",
    "\n",
    "    def cek_repeated_punctuation(self, next_term):\n",
    "        if re.search(r'!{2,}',next_term) and self.score >=3: self.score+=1\n",
    "        if re.search(r'!{2,}',next_term) and self.score <=-3: self.score-=1\n",
    "\n",
    "    def remove_extra_repeated_char(self, term):\n",
    "        return re.sub(r'([A-Za-z])\\1{2,}',r'\\1',term)\n",
    "    def plural_to_singular(self, term):\n",
    "        return re.sub(r'([A-Za-z]+)\\-\\1', r'\\1',term)\n",
    "    \n",
    "    def classify(self):\n",
    "        result = \"neutral\"\n",
    "        try:\n",
    "            if self.mean_conf:\n",
    "                mean_p = np.mean(self.mean_pos)\n",
    "                mean_n = np.mean(self.mean_neg)\n",
    "                print(mean_p, mean_n)\n",
    "                if mean_p > mean_n:\n",
    "                    result = \"positive\"\n",
    "                elif mean_p < mean_n and not self.is_tanya:\n",
    "                    result = \"negative\"\n",
    "                elif mean_p < mean_n and self.is_tanya:\n",
    "                    result = \"neutral\"\n",
    "            else:\n",
    "                if abs(self.sentences_max_pos) > abs(self.sentences_max_neg):\n",
    "                    result = \"positive\"\n",
    "                elif abs(self.sentences_max_pos) < abs(self.sentences_max_neg):\n",
    "                    result = \"negative\"\n",
    "                elif abs(self.sentences_max_pos) == abs(self.sentences_max_neg):\n",
    "                    result = \"neutral\"\n",
    "        except:\n",
    "            print(\"error \",self.sentences_max_pos, self.sentences_max_neg)\n",
    "        return result\n",
    "    def cek_neutral_term(self,terms,i):\n",
    "        if terms[i-1] in self.neutral_term or terms[i+1] in self.neutral_term: self.score=1 \n",
    "\n",
    "    def main(self,sentence):\n",
    "        self.neutral_term = ['jika','kalau']\n",
    "        sentences = sentence.split('.')\n",
    "        self.sentences_max_neg = -1\n",
    "        self.sentences_max_pos = 1\n",
    "        self.sentences_score = []\n",
    "        self.sentences_text = []\n",
    "        for sentence in sentences:\n",
    "            self.max_neg = -1\n",
    "            self.max_pos = 1\n",
    "            self.mean_neg = [1]\n",
    "            self.mean_pos = [1]\n",
    "            self.sentence_score=[]\n",
    "            terms = sentence.split()\n",
    "            # terms = re.split(r'[\\s,.]',sentence)\n",
    "            terms_length = len(terms)\n",
    "            self.is_tanya = False\n",
    "            self.sentence_text = ''\n",
    "            # print self.max_pos, self.max_neg\n",
    "            #SEMUA KALIMAT YANG MEMILIKI TANDA SERU MEMILIKI +ve minimal 2\n",
    "            if self.exclamation_conf and re.search('!',sentence): self.max_pos = 2\n",
    "            self.prev_score = 0\n",
    "            self.pre_max_pos = []\n",
    "            self.pre_max_neg = []\n",
    "            for i,term in enumerate(terms):\n",
    "                # repeated_term = ''\n",
    "                is_extra_char = False\n",
    "                plural = ''\n",
    "                self.score = 0\n",
    "                # if re.search(r'[A-Za-z\\-.]+',term):\n",
    "                # print term\n",
    "                if re.search(r'([A-Za-z])\\1{3,}',term):\n",
    "                    is_extra_char = True\n",
    "                    # repeated_term =term\n",
    "                term = self.remove_extra_repeated_char(term)\n",
    "                if re.search(r'([A-Za-z]+)\\-\\1',term):\n",
    "                    plural = term\n",
    "                    term = self.plural_to_singular(term)\n",
    "                #GET SENTI SCORE#\n",
    "                self.score = self.senti(term)\n",
    "                # print \"senti score\",term, self.score\n",
    "\n",
    "                #NEGATION HANDLER#\n",
    "                if self.negation_conf and self.score !=0 and i>0:self.cek_negationword(terms[i-1],terms[i-2])\n",
    "                # print  \"negation score\",term, self.score\n",
    "\n",
    "                #BOOSTERWORD HANDLER#\n",
    "                if self.booster_conf and self.score !=0 and i>0 and i<=(terms_length-1):self.cek_boosterword(terms[i-1])\n",
    "                if self.booster_conf and self.score !=0 and i>=0 and i<(terms_length-1):self.cek_boosterword(terms[i+1])\n",
    "                # print  \"booster score\",term, self.score\n",
    "\n",
    "                #IDIOM/UNGKAPAN HANDLER#\n",
    "                if self.ungkapan_conf and i>0 and i<=(terms_length-1):self.cek_ungkapan([terms[i-1],term],[terms[i-2],terms[i-1],term],i)\n",
    "                # if self.ungkapan_conf and i>=0 and i<(terms_length-1):self.cek_ungkapan([term,terms[i+1]])\n",
    "                # print  \"idiom score\",term, self.score\n",
    "\n",
    "                #CONSECUTIVE SENTIMENT WORD#\n",
    "                if self.consecutive_conf and i>0 and i<=(terms_length-1) and self.score !=0:self.cek_consecutive_term(terms[i-1])\n",
    "                # print  \"consecutive score\",term, self.score\n",
    "\n",
    "                #+1 SENTI SCORE IF REPEATED CHAR ON POSITIVE/NEGATIVE +2 IF NEUTRAL TERM\n",
    "                if self.repeated_conf and is_extra_char==True and self.score>0: self.score+=1\n",
    "                if self.repeated_conf and is_extra_char==True and self.score<0: self.score-=1\n",
    "                if self.repeated_conf and is_extra_char==True and self.score==0: self.score=2\n",
    "                # print  \"repeat char score\", term, self.score\n",
    "                if self.punctuation_conf and i>=0 and i<(terms_length-1): self.cek_repeated_punctuation(terms[i+1])\n",
    "                # CEK APAKAH TERDAPAT KATA TANYA\n",
    "                if self.question_conf and (term in self.tanya or re.search(r'\\?',term)):self.is_tanya = True\n",
    "                # CEK neutral term \n",
    "                if self.score!=0 and i>1 and i<(terms_length-2): self.cek_neutral_term(terms,i)\n",
    "                # if self.score!=0 and i>0 and i<(terms_length-4): self.cek_neutral_term(terms,i)\n",
    "                if self.emoticon_conf and self.score==0: self.score = self.emosikon(term)\n",
    "\n",
    "                self.prev_score = self.score\n",
    "                if self.mean_conf and self.score>0: self.mean_pos.append(self.score)\t\n",
    "                if self.mean_conf and self.score<0: self.mean_neg.append(abs(self.score))\n",
    "                #GET MAX SCORE +ve/-ve\t\n",
    "                self.max_pos= self.score if self.score > self.max_pos else self.max_pos\n",
    "                self.max_neg= self.score if self.score < self.max_neg else self.max_neg\n",
    "                #insert score info current term\n",
    "                self.pre_max_pos.append(self.max_pos)\n",
    "                self.pre_max_neg.append(self.max_neg)\n",
    "                # print self.pre_max_pos, self.pre_max_neg\n",
    "                if plural !='': term = plural\n",
    "                self.sentence_text += ' {}'.format(term)\n",
    "                if self.score != 0:term = \"{} [{}]\".format(term, self.score)\n",
    "                self.sentence_score.append(term)\n",
    "\n",
    "            self.sentences_text.append(self.sentence_text)\n",
    "            self.sentences_score.append(\" \".join(self.sentence_score))\n",
    "            if self.is_tanya: \n",
    "                self.max_neg = -1\n",
    "            self.sentences_max_pos = self.max_pos if self.max_pos > self.sentences_max_pos else self.sentences_max_pos\n",
    "            self.sentences_max_neg = self.max_neg if self.max_neg < self.sentences_max_neg else self.sentences_max_neg\n",
    "            # print self.sentences_max_pos, self.sentences_max_neg\n",
    "        sentence_result = self.classify()\n",
    "        # print self.sentences_text\n",
    "        return {\"classified_text\":\". \".join(self.sentences_score),\"tweet_text\":\". \".join(self.sentences_text),\"sentence_score\":self.sentences_score,\"max_positive\":self.sentences_max_pos,\"max_negative\":self.sentences_max_neg,\"kelas\":sentence_result}\n",
    "\n",
    "config = dict()\n",
    "config[\"negation\"] = True\n",
    "config[\"booster\"]  = True\n",
    "config[\"ungkapan\"]  = True\n",
    "config[\"consecutive\"]  = True\n",
    "config[\"repeated\"]  = True\n",
    "config[\"emoticon\"]  = True\n",
    "config[\"question\"]  = True\n",
    "config[\"exclamation\"]  = True\n",
    "config[\"punctuation\"]  = True\n",
    "senti = sentistrength(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390a3437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSentistrength(username):\n",
    "    outfile = \"datasets/sentiment-feature.csv\"\n",
    "    with open(outfile, mode='w') as file:\n",
    "        file.write('username,positive,negative,neutral\\n')    \n",
    "        for user in username:\n",
    "            word = []\n",
    "            positive = 0\n",
    "            negative = 0\n",
    "            neutral = 0    \n",
    "            infile = \"datasets/data-tweets/tfidf/tfidf@\" + user + \".csv\"\n",
    "            with open(infile, 'r', encoding='utf-8') as readfile:\n",
    "                next(readfile, None)\n",
    "                for line in readfile:\n",
    "                    Type = line.split(\",\")\n",
    "                    term = Type[0]\n",
    "                    weight = float(Type[1])\n",
    "\n",
    "                    word = senti.main(term)\n",
    "                    if word['kelas'] == 'positive':\n",
    "                        positive += weight * word['max_positive']\n",
    "#                         print(term,positive)\n",
    "                  elif word['kelas'] == 'negative':\n",
    "                        negative += weight * word['max_negative']\n",
    "#                         print(term,negative)\n",
    "                   elif word['kelas'] == 'neutral':\n",
    "                        neutral += weight\n",
    "#                         print(term,neutral)\n",
    "                \n",
    "            file.write(user+','+str(\"%.3f\" %positive)+','+str(\"%.3f\" %negative)+','+str(\"%.3f\" %neutral)+'\\n')\n",
    "\n",
    "    print(\"\\n- writing to '\" + outfile + \"' complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732d7326",
   "metadata": {},
   "outputs": [],
   "source": [
    "getSentistrength(username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49665aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_senti = pd.read_csv('datasets/dict/sentiwords_id.txt', delimiter=\":\", header=None, names=['word','senti'])\n",
    "df_senti = df_senti.set_index('word')\n",
    "dict_senti = df_senti.to_dict()\n",
    "\n",
    "def getSentistrength(username):\n",
    "    outfile = \"datasets/sentiment-feature.csv\"\n",
    "    with open(outfile, mode='w') as file:\n",
    "        file.write('username,positive,negative,neutral\\n')\n",
    "        for user in username:\n",
    "            positive = 0; negative = 0; neutral = 0\n",
    "            infile = \"datasets/data-tweets/tfidf/tfidf@\" + user + \".csv\"\n",
    "            with open(infile, 'r', encoding='utf-8') as readfile:\n",
    "                next(readfile, None)\n",
    "                for line in readfile:\n",
    "                    Type = line.split(\",\")\n",
    "                    term = Type[0]\n",
    "                    weight = float(Type[1])\n",
    "                \n",
    "                    if term in dict_senti['senti']:\n",
    "                        senti = dict_senti['senti'][term]\n",
    "                        if senti > 1 and senti <=5:\n",
    "                            positive += senti * weight\n",
    "#                             print(term, positive)\n",
    "                        elif senti < -1 and senti >=-5:\n",
    "                            negative += senti * weight\n",
    "#                             print(term, negative)\n",
    "                        else:\n",
    "                            neutral += weight\n",
    "#                             print(term, neutral)\n",
    "                    else:\n",
    "                        neutral += weight\n",
    "#                         print(term, neutral)\n",
    "                \n",
    "            file.write(user+','+str(\"%.3f\" %positive)+','+str(\"%.3f\" %negative)+','+str(\"%.3f\" %neutral)+'\\n')\n",
    "    print(\"\\n- Sentiment Analysis Task '\" + outfile + \"' complete.\")           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0be2c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "getSentistrength(username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142e5352",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentFe = pd.read_csv('datasets/sentiment-feature.csv').round(2)\n",
    "socFe = pd.read_csv('datasets/social-feature.csv').round(2)\n",
    "# socFe = pd.read_csv('datasets/crawl-social-all.csv').round(2)\n",
    "\n",
    "for i in range (len(sentFe['username'])):\n",
    "    sentFe['username'].loc[i] = str.lower(sentFe['username'].loc[i])\n",
    "    \n",
    "# using merge function by setting how='right'\n",
    "output = pd.merge(sentFe, socFe, \n",
    "                   on='username', \n",
    "                   how='right')\n",
    "\n",
    "output = output.dropna()\n",
    "output.index = output['username']\n",
    "output = output.drop('username', axis = 'columns')\n",
    "output.to_csv(r'datasets/sentsoc-feature.csv')\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201e6890",
   "metadata": {},
   "source": [
    "# Emotion Analysis\n",
    "Dict by: https://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfb0fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emo = pd.read_excel('datasets/dict/NRC-Emotion-Lexicon-v0.92.xlsx')\n",
    "df_emo = df_emo[['Indonesian (id)','Positive','Negative','Anger','Anticipation','Disgust','Fear','Joy','Sadness','Surprise','Trust']]\n",
    "df_emo = df_emo.drop_duplicates(subset=['Indonesian (id)']).reset_index(drop=True)\n",
    "df_emo['Indonesian (id)'] = df_emo['Indonesian (id)'].str.lower()\n",
    "df_emo.sort_values(by='Indonesian (id)', inplace = True, ignore_index=True) \n",
    "df_emo = df_emo.rename(columns = {'Indonesian (id)': 'Indonesian'}, inplace = False)\n",
    "df_emo = df_emo.set_index('Indonesian')\n",
    "dict_emo = df_emo.to_dict()\n",
    "\n",
    "# from nrclex import NRCLex\n",
    "def getEmolex(username):\n",
    "    outfile = \"datasets/emotion-feature.csv\"\n",
    "    with open(outfile, mode='w') as file:\n",
    "            file.write('username,e_positive,e_negative,anger,anticipation,disgust,fear,joy,sadness,surprise,trust\\n')    \n",
    "            for user in username:\n",
    "                e_positive = 0; e_negative = 0;  anger = 0; anticipation = 0; disgust = 0; \n",
    "                fear = 0; joy = 0; sadness = 0; surprise = 0; trust = 0;\n",
    "                infile = \"datasets/data-tweets/tfidf/tfidf@\" + user + \".csv\"\n",
    "                with open(infile, 'r', encoding='utf-8') as readfile:\n",
    "                    next(readfile, None)\n",
    "                    for line in readfile:\n",
    "                        Type = line.split(\",\")\n",
    "                        term = Type[0]\n",
    "                        weight = float(Type[1])\n",
    "\n",
    "                        if term in dict_emo['Positive']:\n",
    "                            e_positive += weight * dict_emo['Positive'][term]\n",
    "                            e_negative += weight * dict_emo['Negative'][term]\n",
    "                            anger += weight * dict_emo['Anger'][term]\n",
    "                            anticipation += weight * dict_emo['Anticipation'][term]\n",
    "                            disgust += weight * dict_emo['Disgust'][term]\n",
    "                            fear += weight * dict_emo['Fear'][term]\n",
    "                            joy += weight * dict_emo['Joy'][term]\n",
    "                            sadness += weight * dict_emo['Sadness'][term]\n",
    "                            surprise += weight * dict_emo['Surprise'][term]\n",
    "                            trust += weight * dict_emo['Trust'][term]\n",
    "                        \n",
    "                \n",
    "                print(user+','+str(\"%.3f\" %e_positive)+','+str(\"%.3f\" %e_negative)+','+str(\"%.3f\" %anger)+','+str(\"%.3f\" %anticipation)+','+str(\"%.3f\" %disgust)+','+str(\"%.3f\" %fear)+','+str(\"%.3f\" %joy)+','+str(\"%.3f\" %sadness)+','+str(\"%.3f\" %surprise)+','+str(\"%.3f\" %trust)+'\\n')\n",
    "                file.write(user+','+str(\"%.3f\" %e_positive)+','+str(\"%.3f\" %e_negative)+','+str(\"%.3f\" %anger)+','+str(\"%.3f\" %anticipation)+','+str(\"%.3f\" %disgust)+','+str(\"%.3f\" %fear)+','+str(\"%.3f\" %joy)+','+str(\"%.3f\" %sadness)+','+str(\"%.3f\" %surprise)+','+str(\"%.3f\" %trust)+'\\n')\n",
    "    print(\"\\n- writing to '\" + outfile + \"' complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c512f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "getEmolex(username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90125e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentsocFe = pd.read_csv('datasets/sentsoc-feature.csv').round(2)\n",
    "emoFe = pd.read_csv('datasets/emotion-feature.csv').round(2)\n",
    "\n",
    "for i in range (len(sentsocFe['username'])):\n",
    "    sentsocFe['username'].loc[i] = str.lower(sentsocFe['username'].loc[i])\n",
    "for i in range (len(emoFe['username'])):\n",
    "    emoFe['username'].loc[i] = str.lower(emoFe['username'].loc[i])\n",
    "    \n",
    "# using merge function by setting how='right'\n",
    "output = pd.merge(sentsocFe, emoFe, \n",
    "                   on='username', \n",
    "                   how='right')\n",
    "\n",
    "output = output.dropna()\n",
    "output.index = output['username']\n",
    "output = output.drop('username', axis = 'columns')\n",
    "output.to_csv(r'datasets/all-feature.csv')\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd97cd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelData = pd.read_csv('datasets/formulir-ketersediaan.csv')\n",
    "labelData = labelData[['Username Twitter','Kecendrungan']]\n",
    "labelData.rename(columns = {'Username Twitter' : 'username', 'Kecendrungan' : 'label'}, inplace = True)\n",
    "\n",
    "for i in range (len(labelData['username'])):\n",
    "    labelData['username'].loc[i] = re.sub(r'@+', '', labelData['username'].loc[i]) \n",
    "    labelData['username'].loc[i] = str.lower(labelData['username'].loc[i])\n",
    "\n",
    "labelData.index = labelData['username']\n",
    "# labelData.drop('username', axis='columns', inplace=True)\n",
    "labelData = labelData.drop_duplicates(subset=['username']).reset_index(drop=True)\n",
    "labelData\n",
    "\n",
    "\n",
    "feData = pd.read_csv('datasets/all-feature.csv').round(2)\n",
    "output = pd.merge(feData, labelData, \n",
    "                   on='username', \n",
    "                   how='right')\n",
    "\n",
    "output = output.drop_duplicates().reset_index(drop=True)\n",
    "output = output.dropna()\n",
    "output.index = output['username']\n",
    "output = output.drop('username', axis = 'columns')\n",
    "output.to_csv(r'datasets/all-feature-labeled.csv')\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade0eef7",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca04e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('datasets/all-feature-labeled.csv').round(2)\n",
    "dataset = dataset.iloc[0:260]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8a3415",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the dependent variable class\n",
    "factor = pd.factorize(dataset['label'])\n",
    "dataset.label = factor[0]\n",
    "definitions = factor[1]\n",
    "print(dataset.label.head())\n",
    "print(definitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a17a59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_sent = ['positive','negative','neutral']\n",
    "f_soc = ['follower','following','favorite','tweets','retweet','favorited']\n",
    "f_emo = ['e_positive','e_negative','anger','anticipation','disgust','fear','joy','sadness','surprise','trust']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab767742",
   "metadata": {},
   "source": [
    "### Sentiment Feature >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e81042",
   "metadata": {},
   "outputs": [],
   "source": [
    "accSentFeature = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44b3088",
   "metadata": {},
   "source": [
    "#### SentFe - Test Size 10:90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2505af25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "Xsent = dataset[f_sent].values\n",
    "ysent= dataset['label'].values\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = tts(Xsent, ysent, test_size = 0.10, random_state = 42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "RF2= RFC(n_estimators = 500, random_state = 42, min_samples_split = 10) # BEST PARAM TS=01\n",
    "# RF2= RFC() # BASIC PARAM \n",
    "RF2.fit(X_train,y_train)\n",
    "\n",
    "y_pr2= RF2.predict(X_test)\n",
    "\n",
    "reversefactor = dict(zip(range(5),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pr2 = np.vectorize(reversefactor.get)(y_pr2)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pr2, rownames=['Actual Personality'], colnames=['Predicted Personality']))\n",
    "\n",
    "accSentFeature.append(round((accuracy_score(y_pr2, y_test)*100), 2))\n",
    "print('\\n accuracy: ', round((accuracy_score(y_pr2, y_test)*100), 2), '%')\n",
    "print('\\n', classification_report(y_test, y_pr2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7fd2bd",
   "metadata": {},
   "source": [
    "#### SentFe - Test Size 20:80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96072507",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Xsent = dataset[f_sent].values\n",
    "ysent= dataset['label'].values\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = tts(Xsent, ysent, test_size = 0.20, random_state = 42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "RF2= RFC(n_estimators = 550, random_state = 42, min_samples_split = 12)\n",
    "RF2.fit(X_train,y_train)\n",
    "\n",
    "y_pr2= RF2.predict(X_test)\n",
    "\n",
    "reversefactor = dict(zip(range(5),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pr2 = np.vectorize(reversefactor.get)(y_pr2)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pr2, rownames=['Actual Personality'], colnames=['Predicted Personality']))\n",
    "\n",
    "accSentFeature.append(round((accuracy_score(y_pr2, y_test)*100), 2))\n",
    "print('\\n accuracy: ', round((accuracy_score(y_pr2, y_test)*100), 2), '%')\n",
    "print('\\n', classification_report(y_test, y_pr2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183ee694",
   "metadata": {},
   "source": [
    "#### SentFe - Test Size 30:70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27abd668",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Xsent = dataset[f_sent].values\n",
    "ysent= dataset['label'].values\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = tts(Xsent, ysent, test_size = 0.30, random_state = 42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "RF2= RFC(n_estimators = 550, random_state = 42, min_samples_split = 12)\n",
    "RF2.fit(X_train,y_train)\n",
    "\n",
    "y_pr2= RF2.predict(X_test)\n",
    "\n",
    "reversefactor = dict(zip(range(5),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pr2 = np.vectorize(reversefactor.get)(y_pr2)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pr2, rownames=['Actual Personality'], colnames=['Predicted Personality']))\n",
    "\n",
    "accSentFeature.append(round((accuracy_score(y_pr2, y_test)*100), 2))\n",
    "print('\\n accuracy: ', round((accuracy_score(y_pr2, y_test)*100), 2), '%')\n",
    "print('\\n', classification_report(y_test, y_pr2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb50237",
   "metadata": {},
   "source": [
    "#### SentFe - Test Size 40:60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617d87c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Xsent = dataset[f_sent].values\n",
    "ysent= dataset['label'].values\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = tts(Xsent, ysent, test_size = 0.40, random_state = 42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "RF2= RFC(n_estimators = 300, random_state = 42, min_samples_split = 12)\n",
    "RF2.fit(X_train,y_train)\n",
    "\n",
    "y_pr2= RF2.predict(X_test)\n",
    "\n",
    "reversefactor = dict(zip(range(5),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pr2 = np.vectorize(reversefactor.get)(y_pr2)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pr2, rownames=['Actual Personality'], colnames=['Predicted Personality']))\n",
    "\n",
    "accSentFeature.append(round((accuracy_score(y_pr2, y_test)*100), 2))\n",
    "print('\\n accuracy: ', round((accuracy_score(y_pr2, y_test)*100), 2), '%')\n",
    "print('\\n', classification_report(y_test, y_pr2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f22bfbb",
   "metadata": {},
   "source": [
    "#### SentFe - Test Size 50:50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38848f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Xsent = dataset[f_sent].values\n",
    "ysent= dataset['label'].values\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = tts(Xsent, ysent, test_size = 0.50, random_state = 42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "RF2= RFC(n_estimators = 350, random_state = 42, min_samples_split = 18)\n",
    "RF2.fit(X_train,y_train)\n",
    "\n",
    "y_pr2= RF2.predict(X_test)\n",
    "\n",
    "reversefactor = dict(zip(range(5),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pr2 = np.vectorize(reversefactor.get)(y_pr2)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pr2, rownames=['Actual Personality'], colnames=['Predicted Personality']))\n",
    "\n",
    "accSentFeature.append(round((accuracy_score(y_pr2, y_test)*100), 2))\n",
    "print('\\n accuracy: ', round((accuracy_score(y_pr2, y_test)*100), 2), '%')\n",
    "print('\\n', classification_report(y_test, y_pr2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec09c4ed",
   "metadata": {},
   "source": [
    "#### SentFe - Test Size 60:40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fae088",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Xsent = dataset[f_sent].values\n",
    "ysent= dataset['label'].values\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = tts(Xsent, ysent, test_size = 0.60, random_state = 42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "RF2= RFC(n_estimators = 400, random_state = 42, min_samples_split = 12)\n",
    "RF2.fit(X_train,y_train)\n",
    "\n",
    "y_pr2= RF2.predict(X_test)\n",
    "\n",
    "reversefactor = dict(zip(range(5),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pr2 = np.vectorize(reversefactor.get)(y_pr2)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pr2, rownames=['Actual Personality'], colnames=['Predicted Personality']))\n",
    "\n",
    "accSentFeature.append(round((accuracy_score(y_pr2, y_test)*100), 2))\n",
    "print('\\n accuracy: ', round((accuracy_score(y_pr2, y_test)*100), 2), '%')\n",
    "print('\\n', classification_report(y_test, y_pr2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b1862e",
   "metadata": {},
   "source": [
    "#### SentFe - Test Size 70:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57901fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Xsent = dataset[f_sent].values\n",
    "ysent= dataset['label'].values\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = tts(Xsent, ysent, test_size = 0.70, random_state = 42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "RF2= RFC(n_estimators = 450, random_state = 42, min_samples_split = 8)\n",
    "RF2.fit(X_train,y_train)\n",
    "\n",
    "y_pr2= RF2.predict(X_test)\n",
    "\n",
    "reversefactor = dict(zip(range(5),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pr2 = np.vectorize(reversefactor.get)(y_pr2)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pr2, rownames=['Actual Personality'], colnames=['Predicted Personality']))\n",
    "\n",
    "accSentFeature.append(round((accuracy_score(y_pr2, y_test)*100), 2))\n",
    "print('\\n accuracy: ', round((accuracy_score(y_pr2, y_test)*100), 2), '%')\n",
    "print('\\n', classification_report(y_test, y_pr2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ad5b6f",
   "metadata": {},
   "source": [
    "#### SentFe - Test Size 80:20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e06c893",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Xsent = dataset[f_sent].values\n",
    "ysent= dataset['label'].values\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = tts(Xsent, ysent, test_size = 0.80, random_state = 42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "RF2= RFC(n_estimators = 250, random_state = 42, min_samples_split = 2)\n",
    "RF2.fit(X_train,y_train)\n",
    "\n",
    "y_pr2= RF2.predict(X_test)\n",
    "\n",
    "reversefactor = dict(zip(range(5),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pr2 = np.vectorize(reversefactor.get)(y_pr2)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pr2, rownames=['Actual Personality'], colnames=['Predicted Personality']))\n",
    "\n",
    "accSentFeature.append(round((accuracy_score(y_pr2, y_test)*100), 2))\n",
    "print('\\n accuracy: ', round((accuracy_score(y_pr2, y_test)*100), 2), '%')\n",
    "print('\\n', classification_report(y_test, y_pr2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903432f5",
   "metadata": {},
   "source": [
    "#### SentFe - Test Size 90:10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8add0ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Xsent = dataset[f_sent].values\n",
    "ysent= dataset['label'].values\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = tts(Xsent, ysent, test_size = 0.9, random_state = 42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "RF2= RFC(n_estimators = 300, random_state = 42, min_samples_split = 12)\n",
    "RF2.fit(X_train,y_train)\n",
    "\n",
    "y_pr2= RF2.predict(X_test)\n",
    "\n",
    "reversefactor = dict(zip(range(5),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pr2 = np.vectorize(reversefactor.get)(y_pr2)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pr2, rownames=['Actual Personality'], colnames=['Predicted Personality']))\n",
    "\n",
    "accSentFeature.append(round((accuracy_score(y_pr2, y_test)*100), 2))\n",
    "print('\\n accuracy: ', round((accuracy_score(y_pr2, y_test)*100), 2), '%')\n",
    "print('\\n', classification_report(y_test, y_pr2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f887888b",
   "metadata": {},
   "source": [
    "### Social Feature   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5a736f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accSocFeature = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06edbc7d",
   "metadata": {},
   "source": [
    "#### SocFe - Test Size 10:90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ed09f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Xsoc = dataset[f_soc].values\n",
    "ysoc= dataset['label']\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = tts(Xsoc, ysoc, test_size = 0.10, random_state = 42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "RF3= RFC(n_estimators = 450, random_state = 42, min_samples_split = 2)\n",
    "# RF3= RFC(n_estimators = 250, random_state = 42, min_samples_split = 6) # BEST PARAM TS=0.3\n",
    "# RF3= RFC() #BASIC PARAM\n",
    "RF3.fit(X_train,y_train)\n",
    "\n",
    "y_pr3= RF3.predict(X_test)\n",
    "\n",
    "reversefactor = dict(zip(range(5),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pr3 = np.vectorize(reversefactor.get)(y_pr3)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pr3, rownames=['Actual Personality'], colnames=['Predicted Personality']))\n",
    "\n",
    "accSocFeature.append(round((accuracy_score(y_pr3, y_test)*100), 2))\n",
    "print('\\n accuracy: ', round((accuracy_score(y_pr3, y_test)*100), 2), '%')\n",
    "print('\\n', classification_report(y_test, y_pr3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750b512f",
   "metadata": {},
   "source": [
    "#### SocFe - Test Size 20:80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64967e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Xsoc = dataset[f_soc].values\n",
    "ysoc= dataset['label']\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = tts(Xsoc, ysoc, test_size = 0.20, random_state = 42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "RF3= RFC(n_estimators = 200, random_state = 42, min_samples_split = 12)\n",
    "RF3.fit(X_train,y_train)\n",
    "\n",
    "y_pr3= RF3.predict(X_test)\n",
    "\n",
    "reversefactor = dict(zip(range(5),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pr3 = np.vectorize(reversefactor.get)(y_pr3)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pr3, rownames=['Actual Personality'], colnames=['Predicted Personality']))\n",
    "\n",
    "accSocFeature.append(round((accuracy_score(y_pr3, y_test)*100), 2))\n",
    "print('\\n accuracy: ', round((accuracy_score(y_pr3, y_test)*100), 2), '%')\n",
    "print('\\n', classification_report(y_test, y_pr3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c412303",
   "metadata": {},
   "source": [
    "#### SocFe - Test Size 30:70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71979c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Xsoc = dataset[f_soc].values\n",
    "ysoc= dataset['label']\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = tts(Xsoc, ysoc, test_size = 0.30, random_state = 42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "RF3= RFC(n_estimators = 250, random_state = 42, min_samples_split = 6)\n",
    "RF3.fit(X_train,y_train)\n",
    "\n",
    "y_pr3= RF3.predict(X_test)\n",
    "\n",
    "reversefactor = dict(zip(range(5),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pr3 = np.vectorize(reversefactor.get)(y_pr3)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pr3, rownames=['Actual Personality'], colnames=['Predicted Personality']))\n",
    "\n",
    "accSocFeature.append(round((accuracy_score(y_pr3, y_test)*100), 2))\n",
    "print('\\n accuracy: ', round((accuracy_score(y_pr3, y_test)*100), 2), '%')\n",
    "print('\\n', classification_report(y_test, y_pr3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d704ad",
   "metadata": {},
   "source": [
    "#### SocFe - Test Size 40:60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb55804",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Xsoc = dataset[f_soc].values\n",
    "ysoc= dataset['label']\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = tts(Xsoc, ysoc, test_size = 0.40, random_state = 42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "RF3= RFC(n_estimators = 500, random_state = 42, min_samples_split = 14)\n",
    "RF3.fit(X_train,y_train)\n",
    "\n",
    "y_pr3= RF3.predict(X_test)\n",
    "\n",
    "reversefactor = dict(zip(range(5),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pr3 = np.vectorize(reversefactor.get)(y_pr3)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pr3, rownames=['Actual Personality'], colnames=['Predicted Personality']))\n",
    "\n",
    "accSocFeature.append(round((accuracy_score(y_pr3, y_test)*100), 2))\n",
    "print('\\n accuracy: ', round((accuracy_score(y_pr3, y_test)*100), 2), '%')\n",
    "print('\\n', classification_report(y_test, y_pr3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b74346",
   "metadata": {},
   "source": [
    "#### SocFe - Test Size 50:50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad11cb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Xsoc = dataset[f_soc].values\n",
    "ysoc= dataset['label']\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = tts(Xsoc, ysoc, test_size = 0.50, random_state = 42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "RF3= RFC(n_estimators = 200, random_state = 42, min_samples_split = 13)\n",
    "RF3.fit(X_train,y_train)\n",
    "\n",
    "y_pr3= RF3.predict(X_test)\n",
    "\n",
    "reversefactor = dict(zip(range(5),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pr3 = np.vectorize(reversefactor.get)(y_pr3)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pr3, rownames=['Actual Personality'], colnames=['Predicted Personality']))\n",
    "\n",
    "accSocFeature.append(round((accuracy_score(y_pr3, y_test)*100), 2))\n",
    "print('\\n accuracy: ', round((accuracy_score(y_pr3, y_test)*100), 2), '%')\n",
    "print('\\n', classification_report(y_test, y_pr3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064d77ce",
   "metadata": {},
   "source": [
    "#### SocFe - Test Size 60:40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00018d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Xsoc = dataset[f_soc].values\n",
    "ysoc= dataset['label']\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = tts(Xsoc, ysoc, test_size = 0.60, random_state = 42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "RF3= RFC(n_estimators = 350, random_state = 42, min_samples_split = 10)\n",
    "# RF3= RFC()\n",
    "RF3.fit(X_train,y_train)\n",
    "\n",
    "y_pr3= RF3.predict(X_test)\n",
    "\n",
    "reversefactor = dict(zip(range(5),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pr3 = np.vectorize(reversefactor.get)(y_pr3)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pr3, rownames=['Actual Personality'], colnames=['Predicted Personality']))\n",
    "\n",
    "accSocFeature.append(round((accuracy_score(y_pr3, y_test)*100), 2))\n",
    "print('\\n accuracy: ', round((accuracy_score(y_pr3, y_test)*100), 2), '%')\n",
    "print('\\n', classification_report(y_test, y_pr3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db427198",
   "metadata": {},
   "source": [
    "#### SocFe - Test Size 70:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d939489c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Xsoc = dataset[f_soc].values\n",
    "ysoc= dataset['label']\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = tts(Xsoc, ysoc, test_size = 0.70, random_state = 42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "RF3= RFC(n_estimators = 150, random_state = 42, min_samples_split = 2)\n",
    "RF3.fit(X_train,y_train)\n",
    "\n",
    "y_pr3= RF3.predict(X_test)\n",
    "\n",
    "reversefactor = dict(zip(range(5),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pr3 = np.vectorize(reversefactor.get)(y_pr3)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pr3, rownames=['Actual Personality'], colnames=['Predicted Personality']))\n",
    "\n",
    "accSocFeature.append(round((accuracy_score(y_pr3, y_test)*100), 2))\n",
    "print('\\n accuracy: ', round((accuracy_score(y_pr3, y_test)*100), 2), '%')\n",
    "print('\\n', classification_report(y_test, y_pr3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497e51a8",
   "metadata": {},
   "source": [
    "#### SocFe - Test Size 80:20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64050777",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Xsoc = dataset[f_soc].values\n",
    "ysoc= dataset['label']\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = tts(Xsoc, ysoc, test_size = 0.80, random_state = 42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "RF3= RFC(n_estimators = 100, random_state = 42, min_samples_split = 14)\n",
    "RF3.fit(X_train,y_train)\n",
    "\n",
    "y_pr3= RF3.predict(X_test)\n",
    "\n",
    "reversefactor = dict(zip(range(5),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pr3 = np.vectorize(reversefactor.get)(y_pr3)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pr3, rownames=['Actual Personality'], colnames=['Predicted Personality']))\n",
    "\n",
    "accSocFeature.append(round((accuracy_score(y_pr3, y_test)*100), 2))\n",
    "print('\\n accuracy: ', round((accuracy_score(y_pr3, y_test)*100), 2), '%')\n",
    "print('\\n', classification_report(y_test, y_pr3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85592bb",
   "metadata": {},
   "source": [
    "#### SocFe - Test Size 90:10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd3485a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "Xsoc = dataset[f_soc].values\n",
    "ysoc= dataset['label']\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = tts(Xsoc, ysoc, test_size = 0.90, random_state = 42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "RF3= RFC(n_estimators = 300, random_state = 42, min_samples_split = 14)\n",
    "RF3.fit(X_train,y_train)\n",
    "\n",
    "y_pr3= RF3.predict(X_test)\n",
    "\n",
    "reversefactor = dict(zip(range(5),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pr3 = np.vectorize(reversefactor.get)(y_pr3)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pr3, rownames=['Actual Personality'], colnames=['Predicted Personality']))\n",
    "\n",
    "accSocFeature.append(round((accuracy_score(y_pr3, y_test)*100), 2))\n",
    "print('\\n accuracy: ', round((accuracy_score(y_pr3, y_test)*100), 2), '%')\n",
    "print('\\n', classification_report(y_test, y_pr3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6460bc26",
   "metadata": {},
   "source": [
    "### Emotion Feature >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60f0e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "accEmoFeature = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85914f4",
   "metadata": {},
   "source": [
    "#### EmoFe - Test Size 10:90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40718378",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Xemo = dataset[f_emo].values\n",
    "yemo= dataset['label']\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = tts(Xemo, yemo, test_size = 0.10, random_state = 42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "RF4= RFC(n_estimators = 350, random_state = 42, min_samples_split = 12)\n",
    "# RF4= RFC(n_estimators = 450, random_state = 42, min_samples_split = 16) # BEST PARAM TS=0.2\n",
    "# RF4= RFC() #BASIC PARAM\n",
    "RF4.fit(X_train,y_train)\n",
    "\n",
    "y_pr4= RF4.predict(X_test)\n",
    "\n",
    "reversefactor = dict(zip(range(5),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pr4 = np.vectorize(reversefactor.get)(y_pr4)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pr4, rownames=['Actual Personality'], colnames=['Predicted Personality']))\n",
    "\n",
    "accEmoFeature.append(round((accuracy_score(y_pr4, y_test)*100), 2))\n",
    "print('\\n accuracy: ', round((accuracy_score(y_pr4, y_test)*100), 2), '%')\n",
    "print('\\n', classification_report(y_test, y_pr4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a840eac2",
   "metadata": {},
   "source": [
    "#### EmoFe - Test Size 20:80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e5dded",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Xemo = dataset[f_emo].values\n",
    "yemo= dataset['label']\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = tts(Xemo, yemo, test_size = 0.20, random_state = 42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "RF4= RFC(n_estimators = 450, random_state = 42, min_samples_split = 16)\n",
    "RF4.fit(X_train,y_train)\n",
    "\n",
    "y_pr4= RF4.predict(X_test)\n",
    "\n",
    "reversefactor = dict(zip(range(5),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pr4 = np.vectorize(reversefactor.get)(y_pr4)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pr4, rownames=['Actual Personality'], colnames=['Predicted Personality']))\n",
    "\n",
    "accEmoFeature.append(round((accuracy_score(y_pr4, y_test)*100), 2))\n",
    "print('\\n accuracy: ', round((accuracy_score(y_pr4, y_test)*100), 2), '%')\n",
    "print('\\n', classification_report(y_test, y_pr4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68b8f86",
   "metadata": {},
   "source": [
    "#### EmoFe - Test Size 30:70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eeb6edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Xemo = dataset[f_emo].values\n",
    "yemo= dataset['label']\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = tts(Xemo, yemo, test_size = 0.30, random_state = 42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "RF4= RFC(n_estimators = 300, random_state = 42, min_samples_split = 14)\n",
    "RF4.fit(X_train,y_train)\n",
    "\n",
    "y_pr4= RF4.predict(X_test)\n",
    "\n",
    "reversefactor = dict(zip(range(5),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pr4 = np.vectorize(reversefactor.get)(y_pr4)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pr4, rownames=['Actual Personality'], colnames=['Predicted Personality']))\n",
    "\n",
    "accEmoFeature.append(round((accuracy_score(y_pr4, y_test)*100), 2))\n",
    "print('\\n accuracy: ', round((accuracy_score(y_pr4, y_test)*100), 2), '%')\n",
    "print('\\n', classification_report(y_test, y_pr4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896be530",
   "metadata": {},
   "source": [
    "#### EmoFe - Test Size 40:60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d0e4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Xemo = dataset[f_emo].values\n",
    "yemo= dataset['label']\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = tts(Xemo, yemo, test_size = 0.40, random_state = 42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "RF4= RFC(n_estimators = 150, random_state = 42, min_samples_split = 10)\n",
    "RF4.fit(X_train,y_train)\n",
    "\n",
    "y_pr4= RF4.predict(X_test)\n",
    "\n",
    "reversefactor = dict(zip(range(5),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pr4 = np.vectorize(reversefactor.get)(y_pr4)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pr4, rownames=['Actual Personality'], colnames=['Predicted Personality']))\n",
    "\n",
    "accEmoFeature.append(round((accuracy_score(y_pr4, y_test)*100), 2))\n",
    "print('\\n accuracy: ', round((accuracy_score(y_pr4, y_test)*100), 2), '%')\n",
    "print('\\n', classification_report(y_test, y_pr4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae6ff05",
   "metadata": {},
   "source": [
    "#### EmoFe - Test Size 50:50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9727b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Xemo = dataset[f_emo].values\n",
    "yemo= dataset['label']\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = tts(Xemo, yemo, test_size = 0.50, random_state = 42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "RF4= RFC(n_estimators = 450, random_state = 42, min_samples_split = 6)\n",
    "RF4.fit(X_train,y_train)\n",
    "\n",
    "y_pr4= RF4.predict(X_test)\n",
    "\n",
    "reversefactor = dict(zip(range(5),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pr4 = np.vectorize(reversefactor.get)(y_pr4)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pr4, rownames=['Actual Personality'], colnames=['Predicted Personality']))\n",
    "\n",
    "accEmoFeature.append(round((accuracy_score(y_pr4, y_test)*100), 2))\n",
    "print('\\n accuracy: ', round((accuracy_score(y_pr4, y_test)*100), 2), '%')\n",
    "print('\\n', classification_report(y_test, y_pr4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a80c8ca",
   "metadata": {},
   "source": [
    "#### EmoFe - Test Size 60:40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a391b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Xemo = dataset[f_emo].values\n",
    "yemo= dataset['label']\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = tts(Xemo, yemo, test_size = 0.60, random_state = 42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "RF4= RFC(n_estimators = 350, random_state = 42, min_samples_split = 6)\n",
    "RF4.fit(X_train,y_train)\n",
    "\n",
    "y_pr4= RF4.predict(X_test)\n",
    "\n",
    "reversefactor = dict(zip(range(5),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pr4 = np.vectorize(reversefactor.get)(y_pr4)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pr4, rownames=['Actual Personality'], colnames=['Predicted Personality']))\n",
    "\n",
    "accEmoFeature.append(round((accuracy_score(y_pr4, y_test)*100), 2))\n",
    "print('\\n accuracy: ', round((accuracy_score(y_pr4, y_test)*100), 2), '%')\n",
    "print('\\n', classification_report(y_test, y_pr4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db09f639",
   "metadata": {},
   "source": [
    "#### EmoFe - Test Size 70:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7938a23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Xemo = dataset[f_emo].values\n",
    "yemo= dataset['label']\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = tts(Xemo, yemo, test_size = 0.70, random_state = 42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "RF4= RFC(n_estimators = 300, random_state = 42, min_samples_split = 8)\n",
    "RF4.fit(X_train,y_train)\n",
    "\n",
    "y_pr4= RF4.predict(X_test)\n",
    "\n",
    "reversefactor = dict(zip(range(5),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pr4 = np.vectorize(reversefactor.get)(y_pr4)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pr4, rownames=['Actual Personality'], colnames=['Predicted Personality']))\n",
    "\n",
    "accEmoFeature.append(round((accuracy_score(y_pr4, y_test)*100), 2))\n",
    "print('\\n accuracy: ', round((accuracy_score(y_pr4, y_test)*100), 2), '%')\n",
    "print('\\n', classification_report(y_test, y_pr4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2b5f42",
   "metadata": {},
   "source": [
    "#### EmoFe - Test Size 80:20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4532ebd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Xemo = dataset[f_emo].values\n",
    "yemo= dataset['label']\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = tts(Xemo, yemo, test_size = 0.80, random_state = 42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "RF4= RFC(n_estimators = 250, random_state = 42, min_samples_split = 7)\n",
    "RF4.fit(X_train,y_train)\n",
    "\n",
    "y_pr4= RF4.predict(X_test)\n",
    "\n",
    "reversefactor = dict(zip(range(5),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pr4 = np.vectorize(reversefactor.get)(y_pr4)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pr4, rownames=['Actual Personality'], colnames=['Predicted Personality']))\n",
    "\n",
    "accEmoFeature.append(round((accuracy_score(y_pr4, y_test)*100), 2))\n",
    "print('\\n accuracy: ', round((accuracy_score(y_pr4, y_test)*100), 2), '%')\n",
    "print('\\n', classification_report(y_test, y_pr4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e5458d",
   "metadata": {},
   "source": [
    "#### EmoFe - Test Size 90:10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70ed609",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Xemo = dataset[f_emo].values\n",
    "yemo= dataset['label']\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = tts(Xemo, yemo, test_size = 0.90, random_state = 42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "RF4= RFC(n_estimators = 350, random_state = 42, min_samples_split = 18)\n",
    "RF4.fit(X_train,y_train)\n",
    "\n",
    "y_pr4= RF4.predict(X_test)\n",
    "\n",
    "reversefactor = dict(zip(range(5),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pr4 = np.vectorize(reversefactor.get)(y_pr4)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pr4, rownames=['Actual Personality'], colnames=['Predicted Personality']))\n",
    "\n",
    "accEmoFeature.append(round((accuracy_score(y_pr4, y_test)*100), 2))\n",
    "print('\\n accuracy: ', round((accuracy_score(y_pr4, y_test)*100), 2), '%')\n",
    "print('\\n', classification_report(y_test, y_pr4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6c17f6",
   "metadata": {},
   "source": [
    "### All Feature >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42947451",
   "metadata": {},
   "outputs": [],
   "source": [
    "accAllFeature = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bba2245",
   "metadata": {},
   "source": [
    "#### AllFe - Test Size 10:90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b185f647",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X = dataset[f_sent+f_soc+f_emo].values\n",
    "y = dataset['label'].values\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size = 0.10, random_state = 42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "RF1= RFC(n_estimators = 150, random_state = 42, min_samples_split = 2) #BEST PARAM TS=01\n",
    "# RF1= RFC() #BASIC PARAM\n",
    "RF1.fit(X_train,y_train)\n",
    "\n",
    "y_pr1= RF1.predict(X_test)\n",
    "\n",
    "reversefactor = dict(zip(range(5),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pr1 = np.vectorize(reversefactor.get)(y_pr1)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pr1, rownames=['Actual Personality'], colnames=['Predicted Personality']))\n",
    "\n",
    "accAllFeature.append(round((accuracy_score(y_pr1, y_test)*100), 2))\n",
    "print('\\n accuracy: ', round((accuracy_score(y_pr1, y_test)*100), 2), '%')\n",
    "print('\\n', classification_report(y_test, y_pr1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bbe355",
   "metadata": {},
   "source": [
    "#### AllFe - Test Size 20:80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1fa097",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X = dataset[f_sent+f_soc+f_emo].values\n",
    "y = dataset['label'].values\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size = 0.20, random_state = 42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "RF1= RFC(n_estimators = 300, random_state = 42, min_samples_split = 7)\n",
    "# RF1.n_estimators += 100\n",
    "RF1.fit(X_train,y_train)\n",
    "\n",
    "y_pr1= RF1.predict(X_test)\n",
    "reversefactor = dict(zip(range(5),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pr1 = np.vectorize(reversefactor.get)(y_pr1)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pr1, rownames=['Actual Personality'], colnames=['Predicted Personality']))\n",
    "\n",
    "accAllFeature.append(round((accuracy_score(y_pr1, y_test)*100), 2))\n",
    "print('\\n accuracy: ', round((accuracy_score(y_pr1, y_test)*100), 2), '%')\n",
    "print('\\n', classification_report(y_test, y_pr1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fad6a83",
   "metadata": {},
   "source": [
    "#### AllFe - Test Size 30:70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df387b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X = dataset[f_sent+f_soc+f_emo].values\n",
    "y = dataset['label'].values\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size = 0.30, random_state = 42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "RF1= RFC(n_estimators = 500, random_state = 42, min_samples_split = 11)\n",
    "# RF1.n_estimators += 100\n",
    "RF1.fit(X_train,y_train)\n",
    "\n",
    "y_pr1= RF1.predict(X_test)\n",
    "\n",
    "reversefactor = dict(zip(range(5),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pr1 = np.vectorize(reversefactor.get)(y_pr1)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pr1, rownames=['Actual Personality'], colnames=['Predicted Personality']))\n",
    "\n",
    "accAllFeature.append(round((accuracy_score(y_pr1, y_test)*100), 2))\n",
    "print('\\n accuracy: ', round((accuracy_score(y_pr1, y_test)*100), 2), '%')\n",
    "print('\\n', classification_report(y_test, y_pr1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ced3bf",
   "metadata": {},
   "source": [
    "#### AllFe - Test Size 40:60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3bfa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X = dataset[f_sent+f_soc+f_emo].values\n",
    "y = dataset['label'].values\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size = 0.40, random_state = 42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "RF1= RFC(n_estimators = 100, random_state = 42, min_samples_split = 8)\n",
    "# print(RFC.get_params(RF1))\n",
    "# RF1.n_estimators += 100\n",
    "RF1.fit(X_train,y_train)\n",
    "\n",
    "y_pr1= RF1.predict(X_test)\n",
    "\n",
    "reversefactor = dict(zip(range(5),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pr1 = np.vectorize(reversefactor.get)(y_pr1)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pr1, rownames=['Actual Personality'], colnames=['Predicted Personality']))\n",
    "\n",
    "accAllFeature.append(round((accuracy_score(y_pr1, y_test)*100), 2))\n",
    "print('\\n accuracy: ', round((accuracy_score(y_pr1, y_test)*100), 2), '%')\n",
    "print('\\n', classification_report(y_test, y_pr1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe43a786",
   "metadata": {},
   "source": [
    "#### AllFe - Test Size 50:50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be565750",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X = dataset[f_sent+f_soc+f_emo].values\n",
    "y = dataset['label'].values\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size = 0.50, random_state = 42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "RF1= RFC(n_estimators = 150, random_state = 42, min_samples_split = 6)\n",
    "# RF1.n_estimators += 100\n",
    "RF1.fit(X_train,y_train)\n",
    "\n",
    "y_pr1= RF1.predict(X_test)\n",
    "\n",
    "reversefactor = dict(zip(range(5),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pr1 = np.vectorize(reversefactor.get)(y_pr1)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pr1, rownames=['Actual Personality'], colnames=['Predicted Personality']))\n",
    "\n",
    "accAllFeature.append(round((accuracy_score(y_pr1, y_test)*100), 2))\n",
    "print('\\n accuracy: ', round((accuracy_score(y_pr1, y_test)*100), 2), '%')\n",
    "print('\\n', classification_report(y_test, y_pr1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cfe124",
   "metadata": {},
   "source": [
    "#### AllFe - Test Size 60:40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b387f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X = dataset[f_sent+f_soc+f_emo].values\n",
    "y = dataset['label'].values\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size = 0.60, random_state = 42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "RF1= RFC(n_estimators = 450, random_state = 42, min_samples_split = 10)\n",
    "# RF1.n_estimators += 100\n",
    "RF1.fit(X_train,y_train)\n",
    "\n",
    "y_pr1= RF1.predict(X_test)\n",
    "\n",
    "reversefactor = dict(zip(range(5),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pr1 = np.vectorize(reversefactor.get)(y_pr1)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pr1, rownames=['Actual Personality'], colnames=['Predicted Personality']))\n",
    "\n",
    "accAllFeature.append(round((accuracy_score(y_pr1, y_test)*100), 2))\n",
    "print('\\n accuracy: ', round((accuracy_score(y_pr1, y_test)*100), 2), '%')\n",
    "print('\\n', classification_report(y_test, y_pr1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268e24d2",
   "metadata": {},
   "source": [
    "#### AllFe - Test Size 70:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d8cc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X = dataset[f_sent+f_soc+f_emo].values\n",
    "y = dataset['label'].values\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size = 0.70, random_state = 42)\n",
    "\n",
    "# Feature Scaling\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "RF1= RFC(n_estimators = 300, random_state = 42, min_samples_split = 2)\n",
    "# RF1.n_estimators += 100\n",
    "RF1.fit(X_train,y_train)\n",
    "\n",
    "y_pr1= RF1.predict(X_test)\n",
    "\n",
    "reversefactor = dict(zip(range(5),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pr1 = np.vectorize(reversefactor.get)(y_pr1)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pr1, rownames=['Actual Personality'], colnames=['Predicted Personality']))\n",
    "\n",
    "accAllFeature.append(round((accuracy_score(y_pr1, y_test)*100), 2))\n",
    "print('\\n accuracy: ', round((accuracy_score(y_pr1, y_test)*100), 2), '%')\n",
    "print('\\n', classification_report(y_test, y_pr1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9955d3",
   "metadata": {},
   "source": [
    "#### AllFe - Test Size 80:20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ed9a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X = dataset[f_sent+f_soc+f_emo].values\n",
    "y = dataset['label'].values\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size = 0.80, random_state = 42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "RF1= RFC(n_estimators = 550, random_state = 42, min_samples_split = 12)\n",
    "# RF1.n_estimators += 100\n",
    "RF1.fit(X_train,y_train)\n",
    "\n",
    "y_pr1= RF1.predict(X_test)\n",
    "\n",
    "reversefactor = dict(zip(range(5),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pr1 = np.vectorize(reversefactor.get)(y_pr1)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pr1, rownames=['Actual Personality'], colnames=['Predicted Personality']))\n",
    "\n",
    "accAllFeature.append(round((accuracy_score(y_pr1, y_test)*100), 2))\n",
    "print('\\n accuracy: ', round((accuracy_score(y_pr1, y_test)*100), 2), '%')\n",
    "print('\\n', classification_report(y_test, y_pr1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f676c5",
   "metadata": {},
   "source": [
    "#### AllFe - Test Size 90:10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3066e72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "X = dataset[f_sent+f_soc+f_emo].values\n",
    "y = dataset['label'].values\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size = 0.90, random_state = 42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "RF1= RFC(n_estimators = 450, random_state = 42, min_samples_split = 12)\n",
    "# RF1.n_estimators += 100\n",
    "RF1.fit(X_train,y_train)\n",
    "\n",
    "y_pr1= RF1.predict(X_test)\n",
    "\n",
    "reversefactor = dict(zip(range(5),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pr1 = np.vectorize(reversefactor.get)(y_pr1)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pr1, rownames=['Actual Personality'], colnames=['Predicted Personality']))\n",
    "\n",
    "accAllFeature.append(round((accuracy_score(y_pr1, y_test)*100), 2))\n",
    "print('\\n accuracy: ', round((accuracy_score(y_pr1, y_test)*100), 2), '%')\n",
    "print('\\n', classification_report(y_test, y_pr1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbd4205",
   "metadata": {},
   "source": [
    "# Result Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f063435",
   "metadata": {},
   "outputs": [],
   "source": [
    "testSize = ['10:90','20:80','30:70','40:60','50:50','60:40','70:30','80:20','90:10']\n",
    "\n",
    "accuracy = {\n",
    "    'Test Size' : testSize,\n",
    "    'All Feature' : accAllFeature,\n",
    "    'Sentiment Feature' : accSentFeature,\n",
    "    'Social Feature' : accSocFeature,\n",
    "    'Emotion Feature' : accEmoFeature\n",
    "}\n",
    "df_accuracy = pd.DataFrame(accuracy)\n",
    "df_accuracy\n",
    "\n",
    "# meanAllFeature = round(df_accuracy['All Feature'].mean(),2)\n",
    "# meanSentFeature = round(df_accuracy['Sentiment Feature'].mean(),2)\n",
    "# meanSocFeature = round(df_accuracy['Social Feature'].mean(),2)\n",
    "# meanEmoFeature = round(df_accuracy['Emotion Feature'].mean(),2)\n",
    "# new_row = {'Test Size':'Rata-Rata', 'All Feature': meanAllFeature, 'Sentiment Feature':meanSentFeature, 'Social Feature':meanSocFeature, 'Emotion Feature':meanEmoFeature}\n",
    "# df_accuracy = df_accuracy.append(new_row, ignore_index=True)\n",
    "# df_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6267d2c5",
   "metadata": {},
   "source": [
    "#### Best Model - AllFe TestSize 20:80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e20532",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = dataset[f_sent+f_soc+f_emo].values\n",
    "y = dataset['label'].values\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size = 0.20, random_state = 42)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "RF1 = RFC(n_estimators = 300, random_state = 42, min_samples_split = 7) #BEST ALLFE 20:80\n",
    "RF1.fit(X_train, y_train)\n",
    "y_pred = RF1.predict(X_test)\n",
    "\n",
    "dataset['label'] = dataset['label'].replace([0,1,2,3,4],['Conscientiousness', 'Agreeableness', 'Openness', 'Neuroticsm', 'Extroversion'])\n",
    "X = dataset\n",
    "y = dataset['label']\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size = 0.20, random_state = 42)\n",
    "\n",
    "df_pred = pd.DataFrame(y_pred, columns=['predict'])\n",
    "df_pred['predict'] = df_pred['predict'].replace([0,1,2,3,4],['Conscientiousness', 'Agreeableness', 'Openness', 'Neuroticsm', 'Extroversion'])\n",
    "\n",
    "X_test = X_test.reset_index()\n",
    "X_test = X_test.drop(['index'], axis=1)\n",
    "\n",
    "df_cd = pd.concat([X_test, df_pred], axis=1)\n",
    "df_cd.to_csv('datasets/prediction-result.csv')\n",
    "df_cd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45134214",
   "metadata": {},
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f060ea6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BFIScore = pd.read_csv('datasets/formulir-ketersediaan.csv')\n",
    "BFIScore = BFIScore[['Username Twitter','Openness','Conscientiousness','Extroversion','Agreeableness','Neuroticsm',]]\n",
    "BFIScore.rename(columns = {'Username Twitter' : 'username', 'Kecendrungan' : 'label'}, inplace = True)\n",
    "\n",
    "for i in range (len(BFIScore['username'])):\n",
    "    BFIScore['username'].loc[i] = re.sub(r'@+', '', BFIScore['username'].loc[i]) \n",
    "    BFIScore['username'].loc[i] = str.lower(BFIScore['username'].loc[i])\n",
    "    \n",
    "BFIScore.index = BFIScore['username']\n",
    "BFIScore.drop('username', axis='columns', inplace=True)\n",
    "# BFIScore = BFIScore.drop_duplicates(subset=['username']).reset_index(drop=True)\n",
    "BFIScore\n",
    "\n",
    "allFeLabel = pd.read_csv('datasets/all-feature-labeled.csv')\n",
    "allFeLabel\n",
    "\n",
    "output = pd.merge(allFeLabel, BFIScore, \n",
    "                   on='username', \n",
    "                   how='right')\n",
    "\n",
    "output = output.drop_duplicates().reset_index(drop=True)\n",
    "output = output.dropna()\n",
    "output.index = output['username']\n",
    "output = output.drop('username', axis = 'columns')\n",
    "output.to_csv(r'datasets/all-feature-labeled-BFIScore.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e733871",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/all-feature-labeled-BFIScore.csv').round(2)\n",
    "df = df.set_index(['label']).drop('username', axis=1)\n",
    "df = df.abs()\n",
    "df_o = df.loc['Openness'].reset_index()\n",
    "df_c = df.loc['Conscientiousness'].reset_index()\n",
    "df_e = df.loc['Extroversion'].reset_index()\n",
    "df_a = df.loc['Agreeableness'].reset_index()\n",
    "df_n = df.loc['Neuroticsm'].reset_index()\n",
    "\n",
    "df_o = df_o.drop(['Conscientiousness','Extroversion','Agreeableness','Neuroticsm'], axis=1)\n",
    "df_c = df_c.drop(['Openness','Extroversion','Agreeableness','Neuroticsm'], axis=1)\n",
    "df_e = df_e.drop(['Openness','Conscientiousness','Agreeableness','Neuroticsm'], axis=1)\n",
    "df_a = df_a.drop(['Openness','Conscientiousness','Extroversion','Neuroticsm'], axis=1)\n",
    "df_n = df_n.drop(['Openness','Conscientiousness','Extroversion','Agreeableness'], axis=1)\n",
    "\n",
    "corr = {'Openness' : df_o.corr()['Openness'],\n",
    "        'Conscientiousness' : df_c.corr()['Conscientiousness'],\n",
    "        'Extroversion' : df_e.corr()['Extroversion'],\n",
    "        'Agreeableness' : df_a.corr()['Agreeableness'],\n",
    "        'Neuroticism' : df_n.corr()['Neuroticsm']\n",
    "       }\n",
    "df_corr = pd.DataFrame(corr).round(3)\n",
    "df_corr = df_corr.drop(['Openness','Conscientiousness','Extroversion','Agreeableness','Neuroticsm'], axis=0)\n",
    "df_corr = df_corr.transpose()\n",
    "df_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8ceb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplots(figsize = (8,10)) # pendefinisian besar gambar\n",
    "plt.title('Korelasi Antara fitur dan Openness \\n')\n",
    "sns_o = sns.heatmap(df_o.corr()[['Openness']].sort_values(by='Openness', ascending=False), cmap='viridis', linewidths=0.01, annot=True, annot_kws = {'size':14}, fmt='.2g')\n",
    "sns_o.figure.savefig('datasets/corr/corr-openness.png')\n",
    "sns_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eb121e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplots(figsize = (8,10)) # pendefinisian besar gambar\n",
    "plt.title('Korelasi Antara fitur dan Conscientiousness \\n')\n",
    "sns_c = sns.heatmap(df_c.corr()[['Conscientiousness']].sort_values(by='Conscientiousness', ascending=False), cmap='viridis', linewidths=0.01, annot=True, annot_kws = {'size':14}, fmt='.2g')\n",
    "sns_c.figure.savefig('datasets/corr/corr-conscientiousness.png')\n",
    "sns_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5016017",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplots(figsize = (8,10)) # pendefinisian besar gambar\n",
    "plt.title('Korelasi Antara fitur dan Extroversion \\n')\n",
    "sns_e = sns.heatmap(df_e.corr()[['Extroversion']].sort_values(by='Extroversion', ascending=False), cmap='viridis', linewidths=0.01, annot=True, annot_kws = {'size':14}, fmt='.2g')\n",
    "sns_e.figure.savefig('datasets/corr/corr-extroversion.png')\n",
    "sns_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5848cc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplots(figsize = (8,10)) # pendefinisian besar gambar\n",
    "plt.title('Korelasi Antara fitur dan Agreeableness \\n')\n",
    "sns_a = sns.heatmap(df_a.corr()[['Agreeableness']].sort_values(by='Agreeableness', ascending=False), cmap='viridis', linewidths=0.01, annot=True, annot_kws = {'size':14}, fmt='.2g')\n",
    "sns_a.figure.savefig('datasets/corr/corr-agreeableness.png')\n",
    "sns_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d751c21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplots(figsize = (8,10)) # pendefinisian besar gambar\n",
    "plt.title('Korelasi Antara fitur dan Neuroticism \\n')\n",
    "sns_n = sns.heatmap(df_n.corr()[['Neuroticsm']].sort_values(by='Neuroticsm', ascending=False), cmap='viridis', linewidths=0.01, annot=True, annot_kws = {'size':14}, fmt='.2g')\n",
    "sns_n.figure.savefig('datasets/corr/corr-neuroticism.png')\n",
    "sns_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924d57c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrplot = df_corr[f_sent+f_soc+f_emo].plot(kind='bar', figsize=(10, 6), rot=0) #[f_sent]/[f_soc]/[f_emo]\n",
    "corrplot.figure.savefig('datasets/corr/corr-all.png', xlim = 3)\n",
    "corrplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3f03b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
